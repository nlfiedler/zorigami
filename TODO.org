* Tasks
** TODO Replace Flutter with Leptos
*** DONE delete everything Flutter and Dart
*** DONE get a simple page to load [9/9]
- [X] configure Cargo.toml
- [X] feature gate everything in/out
- [X] get =cargo leptos test= to pass
- [X] change =main.rs= to load leptos
- [X] get =cargo leptos watch= to show the home page
- [X] add styles
- [X] add navigation bar
- [X] add favicon
- [X] add dark mode switch
*** DONE rewrite serde for entities
*** DONE look at design of other backup programs
*** TODO pack stores page
*** TODO datasets page
*** TODO snapshots page
*** TODO restore database page
*** TODO test building and running on Windows, update instructions
*** TODO create a =CHANGELOG.md= to record when database schema changes incompatibly
**** include when EXAF was added, changed database and pack files
*** TODO update =Dockerfile=
**** built binary is now called =server= instead of =zorigami=
*** TODO update =README.MD=
*** TODO update =doc/DEPLOY.md=
*** TODO update =doc/DESIGN.md=
*** TODO update =doc/HISTORY.md=
*** TODO write ADR for why Leptos (can copy from tanuki)
** TODO replace =dotenv= with =dotenvy=
** Test improvements
*** sometimes =test_process_manager_async_store()= fails
*** sometimes =test_restorer_fail_then_succeed()= fails
*** make sure a test exists for which only the tree has changed (a file reverted to a previous version)
** Passphrase should be part of the dataset, add to webui
*** should not store in plaintext in database
*** maybe use KDF to create the real "pass phrase" for exaf-rs
*** database backup needs its own pass phrase, probably from environment
** Snapshot retention policy default
*** once webui allows changing retention policy per dataset, change the default to ~ALL~
*** remove the =retention= override in =server/src/data/models/mod.rs= currently =COUNT(3)=
*** fix =update_dataset.rs= to take the correct retention policy type
** Replace minio with SeaweedFS
*** https://github.com/seaweedfs/seaweedfs
** Restore improvements
*** request being processed needs to be returned by =requests()= somehow
**** it is neither ~pending~ nor ~completed~ so it is not returned in queries
**** if the restore supervisor crashes, the in-progress request is lost
**** add a new type that manages the ~pending~ and ~completed~ lists
***** have =Restorer= create this type and pass a =Arc<Mutex>= to supervisor
***** add function for moving the first ~pending~ request to ~processing~
***** add function for updating status of ~processing~ request
***** add function for moving ~processing~ request to the ~completed~ set
***** add function like =requests()= that combines all 3 sets into one for queries
*** restore can hang on pack retrieval for a long time
**** log output
#+begin_src
[2023-08-08T15:34:54Z DEBUG server::domain::managers::restore] fetching pack sha256-9624d9d7cb9dfc37740c121fdbe15f456b6b2153d5b46b3e43feea1cd8db5cbf
[... 15 minutes later ...]
[2023-08-08T15:51:20Z WARN  server::data::repositories] pack retrieval failed, will try another source: Err(Token retrieval failed: error trying to connect: Connection timed out (os error 110))
#+end_src
**** should try to set a timeout to something reasonble (1-2 minutes)
*** add a =status_msg= property to =Request= for showing detailed progress
**** normally show the current path of the file being restore
**** if very large file, show ~fetching very large file~
**** if waiting for a long time for a pack file, indicate in status
*** add the request status field to the graphql entity
*** show the request status message in the web ui
*** web ui should refresh restore requests page every few seconds
** Database Integrity
*** support database integrity checks
**** ensure all referenced records actually exist
**** like git fsck, start at the top and traverse everything
**** find and report dangling objects
**** TODO finish writing =verify_snapshot= use case tests
**** TODO add GraphQL query to invoke =VerifySnapshot= usecase
** Improve backup reliability
*** consider capturing all failed file backups in the database
**** attempt to process the failed files during subsequent backups
*** run a verification step after the backup is complete
*** add some ~debug~ logging at regular intervals during the scan phase
*** report status of the backup (e.g. ~scanning~, ~packing~, ~verifying~)
**** should show the start time, not simply ~still running~
**** show number of files packed, number of packs uploaded (what info logging shows now)
**** capture actual time spent in each phase, accounting for ~pause~ times
** AWS SDK for Rust now available
*** c.f. https://aws.amazon.com/blogs/developer/announcing-general-availability-of-the-aws-sdk-for-rust/
** Efficient restore
*** if restore finds an existing workspace, scan contents to build a ~have~ list of chunks vs starting over
*** if restoring a file over an existing target, skip if checksum of target matches records
**** an integration test exists in =restore_manager_test.rs= that is commented out
** Partial restore
*** using latest snapshot, examine current data set and restore all missing/modified data
*** provide lots of logging and frequent webui status updates
** Snapshot browsing
*** The whole display of snapshots needs to be improved
*** page to show all snapshots over time in a list
*** improve snapshot tree browser
**** should sort entries by filename case-insensitively
**** for larger number of entries, should use pagination
**** nice to have: sticky table header
**** nice to have: sort by file type
*** Have fields for start time, stop time, current status, additional details, etc
*** would be helpful to see all snapshots in which a file or directory changed
** Restore to dissimilar hardware
*** Allow setting the configuration to change the identity
*** Test by restoring a backup to a different system
** Dynamic bucket allocation
*** hard-coded value of 128 is pretty low for local pack stores
*** cloud-based pack stores can accommodate many objects per bucket
*** could consider how frequently new packs are created (1 per day vs hundreds)
** Bucket collision and renaming
*** ~prune extra~ and ~find missing~ will mistakenly remove objects from pack stores
**** need to consider the buckets and objects that may have been renamed by the pack store
** File changes during backup
*** what if a file changes between the snapshot and the backup? is there a better approach
*** if a file changes between snapshot and packing, it will get backed up again the next time
*** large files will get chunked and therefore not backed up twice
** Manage user passphrase
*** introduce a setup phase in which user is prompted for passphrase
*** store passphrase in the local key store
*** consider how to change the passphrase but retain old ones for decrypting packs
** Loose backend issues
*** maybe use a thread pool for bridging async barrier in data sources
**** currently the data sources all spawn a new thread every time
*** neat way to getting filenames in a streamlined manner
**** c.f. https://fettblog.eu/refactoring-rust-abstraction-newtype/
*** should clean up dataset workspaces on startup and periodically
**** need to be sure no backup or restore is running, then delete everything in =.tmp=
**** =State= could have a =is_quiet()= check or an event that be be subscribed to when everything is quiet
*** refine use of =&str= and =String= arguments by using =Into<String>=
**** c.f. https://jwilm.io/blog/from-str-to-cow/ for explanation
**** note that using =Cow= helps to minimize copying
#+BEGIN_SRC rust
pub fn name<T: Into<String>>(mut self, name: T) -> Self {
    self.name = Cow::Owned(name.into());
    self
}
#+END_SRC
*** Too many open files (in RocksDB)
**** need to set =set_max_open_files()= on database options
**** default ulimit on macOS is 256, so something less would be ideal
**** ran out of files in tanuki when rocksdb directory contained 217 files
**** maybe consider a means of countering this error at runtime
** Loose WebUI tasks
*** test with a smaller browser window to surface sizing issues
*** local store basepath and google credentials should use file picker
*** improve (server) error handling
**** when a temporary server error occurs, offer a "Retry" button
*** consider how to hide the minio secret key using a show/hide button
*** should sort the datasets so they are always in the same order
*** tree entries of =ERROR= type should be displayed as such
**** error message from =TreeEntry.new()= could be stored as a new type of =TreeReference=
***** e.g. =TreeReference.ERROR(String)= where the string is the error message
*** use breadcrumbs in the tree navigator to get back to parent directories
** Improved error handling
*** webui: database restore fails to get archive, should display a sensible error
**** cause 1: include mismatching instance identifier
**** cause 2: wrong user owns the files
**** response from backend looks like:
#+begin_src javascript
{
  "data": null,
  "errors": [
    {
      "message": "database archive retrieval",
      "locations": [
        {
          "line": 2,
          "column": 3
        }
      ],
      "path": [
        "restoreDatabase"
      ]
    }
  ]
}
#+end_src
*** webui: change =ServerFailure= to capture original error cause, not just as a string
**** add factory function that detects common types of errors and produces more helpful failure messages
**** e.g. backend is not responding on home screen, shows ugly stack trace
*** Detect cloud credential issues and display friendly message
**** errors from cloud providers can be cryptic, need to detect and decipher for the user
*** Collect and present errors encountered during the backup
**** e.g. all the "permission denied" and such
*** Data set input validation
**** Ask backend to verify the entered basepath before trying to save
*** Pack store input validation
**** should validate Google Cloud service account key when defining pack
*** Consider a structured design for error types and handling
**** c.f. https://fettblog.eu/rust-enums-wrapping-errors/
*** Look at https://github.com/dtolnay/thiserror for defining error types
** Remote pack store interaction
*** Remote pack stores like Google Cloud have built-in limits for certain operations
**** need to consider that GCS will limit the number of buckets listed to 1,000
**** probably minio and S3 have similar default limits
**** the API generally offers a means of paging to get everything in chunks
** Remove files/folders from backup
*** Allow removing files from existing backups
**** e.g. accidentally saved large binaries
** Pack file and database backup pruning
*** add =upload_time= field to =Pack= record in order to determine age
*** add a ~retention policy~ to pack store type
**** initially retention policy would be ~delete after N days~ or retain all
**** provide default value for ~N~ for each cloud provider
**** default value would also likely depend on the chosen storage class
**** e.g. typically anything older than 90 days costs nothing to delete
**** Google has different minimum storage durations for each storage class
***** https://cloud.google.com/storage/docs/storage-classes
*** find unreferenced pack files and remove
**** procedure
1) collect all pack record digests
2) scan all file and chunk records
3) remove reachable pack digests from hash set
4) for each remaining pack, get locations, delete objects, delete pack record
*** database backups to be removed according to pack store retention policy
** Advanced Scheduling
*** backend
**** Permit ~hourly~ backups every N hours
**** Permit ~daily~ backups every N days
**** Permit ~weekly~ backups every N weeks
**** Permit ~monthly~ backups every N months
*** frontend
**** Support multiple schedules in interface
**** Support day-of-week in schedule
**** Support day-of-month in schedule
**** Support week-of-month in schedule
**** Support time-range in schedule
** Filters for excluding files by size
*** allow adding rules on a dataset to ignore files that are too small/large
** Point-in-time snapshots
*** Backup procedure is file-by-file, which may yield broken snapshots
**** e.g. database files can change during the backup, leading to invalid snapshots
*** If available, use the OS functionality for FS snapshots
**** ZFS has snapshot support
**** APFS has snapshots, not sure what they are exactly
***** how to determine that FS supports this feature?
***** use =tmutil= to create, mount, and remove snapshots
#+begin_src shell
$ tmutil localsnapshot
Created local snapshot with date: 2021-04-05-162425

$ tmutil listlocalsnapshots /
Snapshots for volume group containing disk /:
com.apple.TimeMachine.2021-04-05-162416.local
com.apple.TimeMachine.2021-04-05-162425.local

# mount a specific snapshot
mkdir -p /tmp/snapshot
mount_apfs -s com.apple.TimeMachine.2021-04-05-162416.local / /tmp/snapshot
open /tmp/snapshot

$ tmutil deletelocalsnapshots 2021-04-05-162416
Deleted local snapshot '2021-04-05-162416'
#+end_src
** More Functionality
*** search snapshots to find a file/directory by a given pattern
**** the file/dir is not in the latest snapshot but some older one, go find it
**** might not even know the full path of the file/dir in question
*** store restore requests in database to tolerate application restart
**** currently restore requests are queued in memory only, so a crash means everything is forgotten
*** Perform a full backup on demand, discard all previous backups
**** Wifey doesn't like the idea of accumulating old stuff
**** Gives the user a chance to save space by removing old content
**** remove all records that are _not_ stores and datasets
- latest/
- chunk/
- pack/
- file/
- xattr/
- dbase/
- tree/
**** Optionally prune all existing packs in the process
*** event dispatching for the web interface
**** use the state management to manage "events" and state
**** engine emits actions/events to the store
***** for backup and restore functions
***** e.g. "downloaded a pack", "uploaded a pack"
**** store holds the cumulative data so late attachers can gather everything
**** supervisor threads register as subscribers to the store
**** clients will use GraphQL subscriptions to receive updates
**** supervisor threads emit GraphQL subscription events
*** consider how datasets can be modified after creation
**** cannot change stores assigned to dataset once there are snapshots
**** basically would require starting over if changing stores, base path, etc
*** Secure FTP improvements
**** SFTP is twice as slow as MinIO, should investigate why
**** support SFTP with private key authentication
***** use store form to take paths for public and private keys
**** allow private key that is locked with a passphrase
***** passphrase for private key would be provided by envar
*** Repair missing pack files in pack stores
**** expose the GraphQL operation via the graphical interface
** More Information
*** track start and finish time for a backup
**** account for time when backup is paused due to schedule
*** show differences between any two snapshots
**** collect the paths and sizes of all new/changed files
**** somehow show all of that information in a scalable fashion
*** show =fileCounts= query for each of latest N snapshots to show recent data growth
*** Show details about snapshots and files
**** show differences between two snapshots
**** show pack/chunk metrics for   all   files in a snapshot
**** show pack/chunk metrics for changed files in a snapshot
*** Query to see histogram of file sizes, number of chunks, etc
**** for a given snapshot
***** count number of files with N chunks for all values of N
*** Show number of packs stored in a pack store
** Architecture Review
*** document this somewhere: https://gist.github.com/quad/bc2351e2df4a4a815f8e0d19f36cfa80
*** Alternative databases
**** some records are not suitable for relational DB, such as trees, chunks, and packs
**** DuckDB
**** SQLite
*** Rust dependency injection, is it helpful?
**** https://github.com/AzureMarker/shaku
**** https://github.com/p0lunin/teloc
**** https://github.com/hampusmat/syrette
**** https://github.com/mineichen/minfac
**** https://github.com/austinjones/lifeline-rs (whole runtime message bus system)
**** https://github.com/dmitryb-dev/waiter
**** https://github.com/tobni/inject-rs
*** Actor framework review, is actix still good?
**** https://github.com/slawlor/ractor aims to be like Erlang
**** no framework, just tokio: https://ryhl.io/blog/actors-with-tokio/
*** Database per dataset directory
**** Centralized configuration in a known location
***** would default to something sensible in user home directory
***** overridden by environment variable
***** JSON or XML formatted plain text file
***** Holds paths to the various data sets
***** Holds pack store configuration
**** Each data set directory has a database directory (and backup)
**** Backup process automatically excludes the database and its backup
**** What would a full restore procedure look like?
**** Benefits
***** reduced risk in the event of database corruption
**** Drawbacks
***** additional disk usage for database overhead
***** forces user to keep database with the dataset
*** Parallel backups
**** Currently the backup supervisor spawns a single thread (=Arbiter=) to manage backups
**** This causes all backups to be serialized
**** For parallel backups, would use the =SyncArbiter= from actix
*** Database migrations
**** Use the =serde= crate features (c.f. https://serde.rs)
**** Use =#[serde(default)]= on struct to fill in blanks for new fields
**** Add =#[serde(skip_serializing)]= to a deprecated struct field
**** New fields will need accessors that convert from old fields as needed
***** reset the old field to indicate it is no longer relevant
**** Removing a field is no problem for serde
*** Shared pack repository
**** Current design basically forces each user/install to have a separate pack repo
**** Otherwise the pack pruning would delete the packs for other users saving to the same repo
** Full Restore
*** Procedure for full restore
**** User installs and configures application
**** User invokes "full restore" function
**** User provides a temporary pack store configuration
**** Query pack store to get candidate computer UUID values
**** User chooses database to restore
***** if current UUID matches one in the available set, select it by default
**** Fetch the most recent database files
***** Restore to a different directory, then copy over records
***** Copy every record except for =configuration= (and maybe others?)
***** Copy records for datasets, stores, snapshots, packs, etc
**** User can now browse datasets and restore as usual
**** Restoring an entire dataset is simply the "tree restore" case
*** Walk the user through the process
**** Configure the primary pack store for retrieval
**** Inform user that this pack store configuration is only temporary
**** Select database to retrieve based on computer UUID
**** Instruct user to restore as usual from dataset(s)
*** Restore file attributes from tree entry
**** TODO File mode
**** TODO File user/group
**** TODO File extended attributes
*** Restore directories from snapshot
**** restoring an empty directory does nothing, should create the directory
**** restore directory mode bits, user/group ownership, extended attributes
*** Detect and prune stale snapshots that never completely uploaded
**** Stale snapshots exist in the database but are not referenced elsewhere
*** Support snapshots consisting only of mode/owner changes
**** i.e. no file content changes, just the database records
** More Better
*** Ransomware protection
**** descriptions of what this means
***** CloudBerry
: CloudBerry Backup detects encryption changes in files and prevents existing
: backups from being overwritten until an administrator confirms if there is an
: issue.
***** Arq:
: Ransomware protection - point-in-time recovery of files
***** https://ruderich.org/simon/notes/append-only-backups-with-restic-and-rclone
: One issue with most backup solutions is that an attacker controlling the local
: system can also wipe its old backups. To prevent this the backup must permit
: append-only backups (also called add-only backups).
****** They change the SSH config to run the backup command with "append only" flag.
*** Permit scheduling upload hours for each day of the week
**** e.g. from 11pm to 6am Mon-Fri, none on Sat/Sun
*** GraphQL mutation to dump/load database to json
*** Support deduplication across multiple computers
**** Place the chunks and packs in a seperate "database" for syncing
***** For RocksDB, use a column family if it helps with =GetUpdatesSince()=
**** RocksDB replication story as of 2019-02-20:
: Q: Does RocksDB support replication?
: A: No, RocksDB does not directly support replication. However, it offers
: some APIs that can be used as building blocks to support replication.
: For instance, GetUpdatesSince() allows developers to iterate though all
: updates since a specific point in time.
***** see =GetUpdatesSince()= and =PutLogData()= functions
**** User configures the host name of the ~peer~ installation
***** Use that to form the URL with which to =sync=
**** Share the chunks and packs documents with a ~peer~ installation
**** At the start of backup, sync with the ~peer~ to get latest chunks/packs
*** Consider how to deal with partial uploads
**** e.g. Minio/S3 has a means of handling these
*** Permit removing a store from a dataset
**** would encourage user to clean up the remote files
**** for local store, could remove the files immediately
**** must invalidate all of the snapshots effected by the missing store
*** Permit moving from one store to another
**** would mean downloading the packs and uploading them to the new store
* Documentation
** Duplicati has a fun description of how the backup works
*** files are broken into "bricks" which go in "bags" and stored in big "boxes" (the pack store)
*** c.f. https://duplicati.readthedocs.io/en/latest/01-introduction/
* Technical Information
** Backup metrics
*** 2023-08-11, 8 cores, 32gb RAM, 4-disk RAID-Z to minio on LAN, 346gb of data
**** backup complete after 9 hours 48 minutes 11 seconds
**** record counts after 1 snapshot
| type   |  count |
|--------+--------|
| chunks |  47751 |
| files  | 134745 |
| packs  |   4133 |
| trees  |  37143 |
| xattrs |      0 |
**** =fileCounts= sans =fileSizes= (which are shown below)
| description |  count |
|-------------+--------|
| total files | 152181 |
| directories |  37356 |
| symlinks    |      0 |
| very small  |   1576 |
| very large  |      3 |
**** =fileSizes=
|      power | count |
|------------+-------|
|         64 |   402 |
|        128 |  2189 |
|        256 |  3431 |
|        512 |  4201 |
|       1024 |  8947 |
|       2048 | 25343 |
|       4096 |  4747 |
|       8192 |  1804 |
|      16384 |  5731 |
|      32768 | 12277 |
|      65536 | 23297 |
|     131072 |  4169 |
|     262144 | 10009 |
|     524288 |  6064 |
|    1048576 |  9046 |
|    2097152 | 23288 |
|    4194304 |  3383 |
|    8388608 |   497 |
|   16777216 |   288 |
|   33554432 |   402 |
|   67108864 |   444 |
|  134217728 |   311 |
|  268435456 |   217 |
|  536870912 |    99 |
| 1073741824 |    17 |
| 2147483648 |     7 |
| 4294967296 |     1 |
** Restore statistics
*** 4 hours to restore 63GB (11k files) of ~tanuki~ data from Google over fiber
** Performance improvements
*** Parallelism
**** more threads means more disk thrashing; SSD is well-suited to this approach
**** shortening snapshot time
***** mini parallelism is 8
***** server parallelism is 4
***** mini before: 555706 files after 3 minutes 2 seconds (original)
***** mini after: 556625 files after 1 minutes 27 seconds (initial)
***** mini after: 571056 files after 1 minutes 23 seconds (subsequent)
***** server before: 147769 files after 1 hours 20 minutes (original)
***** server after: 147769 files after 52 minutes (initial)
***** server after: 148142 files after 52 minutes (subsequent)
*** SHA256 vs BLAKE3
**** server before: 148142 files after 52 minutes (months ago)
**** server after: 152166 files after 42 minutes
** Error Handling
*** what happens to file errors during scanning?
**** any errors during scan result in the entry being completely ignored
**** they will be processed again on the next scan
*** what happens to file errors during packing?
**** if metadata or opening file fails, recorded as having zero length
**** if packing file fails, overall backup will fail
*** what happens when file contents change between scanning and packing?
**** changed file is stored using the original checksum
**** file will subsequently be (needlessly) backed up again next time
** Data Growth
*** main server
**** better pack file generation
***** average pack size ~before~ change: 68,647,434
***** average pack size ~after~ change: 67,688,886
**** original database schema
***** compressed database seems to grow 8mb in 6 months
***** compressed database size: 61,920,768
**** record counts over time
***** as of 2022-03-17
| entity    |  count |
|-----------+--------|
| snapshots |    576 |
| files     | 137081 |
| trees     |  97598 |
| chunks    | 190758 |
| packs     |   4282 |
| xattrs    |  19263 |
***** as of 2023-01-14
| entity    |  count |
|-----------+--------|
| snapshots |    272 |
| files     | 134950 |
| trees     |  65312 |
| chunks    |  56813 |
| packs     |   4107 |
| xattrs    |  18035 |
*** mac mini statistics
**** original database schema
***** 2022-03-15
****** compressed database size: 2,379,181,138
****** database record counts
| entity    |   count |
|-----------+---------|
| snapshots |     190 |
| files     | 1806620 |
| trees     |  302860 |
| chunks    | 1830167 |
| packs     |    3380 |
| xattrs    |  185473 |
**** with file/chunk record optimization
***** 2022-03-18
****** compressed database size: 454,232,580
****** database record counts
| entity    |  count |
|-----------+--------|
| snapshots |      1 |
| files     | 412555 |
| trees     |  48927 |
| chunks    |   4025 |
| packs     |    369 |
| xattrs    |  14388 |
****** only 1% of files are larger than a chunk
**** with new packing algorithm
***** 2022-03-22
****** compressed database size: 462,090,768
****** database record counts
| entity    |  count |
|-----------+--------|
| snapshots |      1 |
| files     | 457980 |
| trees     |  52844 |
| chunks    |   4061 |
| packs     |    176 |
| xattrs    |  13624 |
**** better pack file generation
***** average pack size ~before~ change: 46,960,186
***** average pack size ~after~ change: 70,496,178
**** very small files in database
***** 2022-03-26
****** compressed database size: 463,418,613
****** database record counts
| entity    |  count |
|-----------+--------|
| snapshots |      1 |
| files     | 437775 |
| trees     |  53499 |
| chunks    |   4185 |
| packs     |    188 |
| xattrs    |  12808 |
****** file counts
| type           |  count |
|----------------+--------|
| directories    |  73536 |
| symlinks       |  14543 |
| filesBelow80   |  56407 |
| filesBelow1k   | 293740 |
| filesBelow10k  | 351019 |
| filesBelow100k |  88622 |
| filesBelow1m   |  11461 |
| filesBelow10m  |   2322 |
| filesBelow100m |    222 |
| veryLargeFiles |     16 |
**** working file excludes
***** 2022-03-27
****** compressed database size: 70,466,060
****** database record counts
| entity    |  count |
|-----------+--------|
| snapshots |      1 |
| files     | 321419 |
| trees     |  40786 |
| chunks    |   1533 |
| packs     |     67 |
| xattrs    |    350 |
****** file counts
| type           |  count |
|----------------+--------|
| directories    |  45074 |
| symlinks       |    672 |
| filesBelow80   |  52633 |
| filesBelow1k   | 135193 |
| filesBelow10k  | 311948 |
| filesBelow100k |  65487 |
| filesBelow1m   |   5531 |
| filesBelow10m  |    789 |
| filesBelow100m |    164 |
| veryLargeFiles |      7 |
** Pack files
*** analysis of overly large pack files before accounting for tar entry overhead
**** packing would only account for compressed size of chunks
**** with many small files, tar file overhead increased file size by half (99mb vs 64mb)
| pack digest | count |  file sz | content len | smallest | largest | average |
|-------------+-------+----------+-------------+----------+---------+---------|
| 3fa54d0     | 19193 | 82480128 |    67114835 |       22 | 4755936 |    3496 |
| b93402d     | 39932 | 99137536 |    67109129 |       39 |  446087 |    1680 |
| c57960e     | 38894 | 98344448 |    67111246 |       40 |  452424 |    1725 |
| ef6ff7a     | 40001 | 99184640 |    67111284 |       40 |  492592 |    1677 |
** Possible corner cases
*** Database backup, then restore, then pack prune
Because the database snapshot is recorded in the database after the snapshot
has already been uploaded, if the user were to restore the database and then
perform a pack pruning, the most recent database snapshot would be removed.
