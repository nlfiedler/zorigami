* Zorigami
** GraphQL and WebUI
*** TODO Test the GraphQL schema and resolvers
**** TODO "integers" that are not radix 10 integers
**** TODO digests that lack the proper algorithm prefix
**** TODO querying for things when there is nothing in the database
**** TODO querying snapshots
**** TODO querying trees
**** TODO querying files
**** DONE fetching configuration record
**** TODO updating configuration record
**** DONE querying datasets
**** DONE mutating datasets
**** DONE querying stores
**** DONE mutating stores
*** TODO How to document arguments to mutations in GraphQL?
*** TODO Need a way to handle error in getting Database ref in graphql handler
*** TODO Write a ReasonML frontend
**** DONE Add =bs-platform= dependency and =bsconfig.json= file
**** DONE Put the bucklescript output into =lib/js=
**** DONE Set up =gulp= and =webpack= to build the front-end code
**** DONE Ensure Rust web server serves compiled JavaScript
**** DONE Add bulma and fontawesome for styling
**** TODO Set up apollo client dependency and schema tooling
**** TODO Write a simple home page that shows something
**** TODO Set up the reason-react routing
**** TODO Store configuration is base64 encoded JSON values
***** c.f. https://github.com/glennsl/bucklescript-cookbook#encode-and-decode-base64
#+BEGIN_SRC
external btoa : string -> string = "" [@@bs.val]
external atob : string -> string = "" [@@bs.val]

let () =
  let text = "Hello World!" in
  Js.log (text |> btoa);
  Js.log (text |> btoa |> atob)
#+END_SRC
**** TODO Manage stores, datasets, and configuration
***** generate cron-like schedules based on checkboxes for datasets
****** e.g. "daily" produces =@daily=, "hourly" produces =@hourly=
*** TODO Loose ends from Rust translation
**** TODO Set up configuration for dev and testing
***** TODO replace hard-coded db_path in integration test
** kohaku Server Backup
*** DONE Get encryption password from an environment variable
*** TODO Support SFTP with private key authentication
**** TODO allow private key locked with passphrase
*** TODO Use this to replace =replicaz= by persisting to USB drive
*** TODO Use this to replace =replicaz= by persisting over SFTP
** Robustness and Recovery
*** TODO Detect files changing between snapshot and pack building time
**** use the =changed= record property to track this
*** TODO Detect file deletion during backup, mark file record as skipped
**** Basically handle the error and mark the record as "failed"
*** TODO Verify checksum of downloaded packs during restore
*** TODO Recover from a backup thread that panicked
**** For each spawned backup thread, spawn a supervisor thread
**** Supervisor thread joins the backup thread
**** If the =Result= from =JoinHandle.join()= is =Err=, then restart
**** see also example on docs for =std::thread::panicking()=

*** TODO How to recover from the main supervisor thread panicking?
**** Perhaps rely on cron, launchd, etc to keep things running
*** TODO Handle termination signals to exit even if backup is running
**** leave the cleanup process for next time
*** TODO Maybe use thread pools and futures in supervisor
**** futures would help with reporting errors back to the main thread
** More Functionality
*** TODO Event dispatching for the web and desktop
**** use the rust redux crate to manage "events" and state
**** engine emits actions/events to the store
***** for backup and restore functions
***** e.g. "downloaded a pack", "uploaded a pack"
**** store holds the cumulative data so late attachers can gather everything
**** supervisor threads register as subscribers to the store
**** clients will use GraphQL subscriptions to receive updates
**** supervisor threads emit GraphQL subscription events
*** TODO Support excluding certain file patterns from backup
*** TODO Exclude the database files from the dataset(s)
*** TODO Consider how datasets can be modified after creation
**** should their stores be allowed to change?
**** should their basepath be allowed to change?
**** cannot change stores assigned to dataset once there are snapshots
*** TODO Enable configuring various overrides in a dataset
**** upload schedule
**** file exclusions
** Google Backup
*** TODO Store database in a bucket named after the "computer UUID"
**** pack file should be a ULID so that the most recent entry is sorted last
*** TODO Support scheduling upload times, like akashita does
**** Define a set of hours each day when uploads should occur
**** Can make use of [[https://crates.io/crates/chrono][chrono]] crate for time related operations
*** TODO Store pack files in Google Cloud Storage
**** Check for bucket name collisions and retry in pack store
**** https://cloud.google.com/storage/docs/best-practices
*** TODO Use this to replace =akashita= for online backups
** macOS support
*** TODO Ensure termination signals are handled even during a backup
*** TODO Use =launchd= to manage the process, have it start automatically
*** TODO Use this to replace Time Machine (store on server using SFTP)
** Full Restore
*** TODO Restore file attributes from tree entry
**** TODO File mode
**** TODO File user/group
**** TODO File extended attributes
*** TODO Restore directories from snapshot
**** TODO Directory mode
**** TODO Directory user/group
**** TODO Directory extended attributes
**** TODO Restore multiple files efficiently
**** TODO Restore a directory tree efficiently
*** TODO Detect and prune stale snapshots that never completely uploaded
**** Stale snapshots exist in the database but are not referenced elsewhere
*** TODO Support snapshots consisting only of mode/owner changes
**** i.e. no file content changes, just the database records
*** TODO Restore the backup database
**** TODO Restore to a different directory, then copy over records
** Windows support
*** TODO Try building on Windows
*** TODO Support Windows file types
**** ReadOnly
**** Hidden
**** System
** More Better
*** TODO Automatically prune backups more then N days old
**** For Google and Amazon, anything older than 90 days is free to remove
**** This would be a configuration setting, with defaults and path-specific
*** TODO Option to keep N daily, M weekly, and P monthly backups (a la Attic backup)
*** TODO Permit scheduling upload hours for each day of the week
**** e.g. from 11pm to 6am Mon-Fri, none on Sat/Sun
*** TODO Command-line option to dump database to json (separate by key prefix, e.g. ~chunk~)
*** TODO Ability to pause or cancel a backup
*** TODO Support deduplication across multiple computers
**** Place the chunks and packs in a seperate "database" for syncing
***** For RocksDB, use a column family if it helps with =GetUpdatesSince()=
**** RocksDB replication story as of 2019-02-20:
: Q: Does RocksDB support replication?
: A: No, RocksDB does not directly support replication. However, it offers
: some APIs that can be used as building blocks to support replication.
: For instance, GetUpdatesSince() allows developers to iterate though all
: updates since a specific point in time.
***** see =GetUpdatesSince()= and =PutLogData()= functions
**** User configures the host name of the ~peer~ installation
***** Use that to form the URL with which to =sync=
**** Share the chunks and packs documents with a ~peer~ installation
**** At the start of backup, sync with the ~peer~ to get latest chunks/packs
*** TODO Consider how to deal with partial uploads
**** e.g. Minio/S3 has a means of handling these
*** TODO Design garbage collection solution (see NOTES)
*** TODO Pack store should recommend pack sizes
**** e.g. Glacier recommends archives greater than 100mb
**** can only really make a recommendation, the user has to choose the right size
*** TODO Permit removing a store from a dataset
**** would encourage user to clean up the remote files
**** for local store, could remove the files immediately
**** must invalidate all of the snapshots effected by the missing store
*** TODO Permit moving from one store to another
**** would mean downloading the packs and uploading them to the new store
*** TODO Support Amazon S3, Minio
**** Need to limit number of remote buckets to 100
**** Bucket limit: catch the error and handle by re-using another bucket
*** TODO Support Amazon Glacier
**** Need to limit number of remote buckets to 1000
**** Use S3 to store the database-to-archive mapping of each snapshot
**** Offer user option to use "expedited" retrievals so they go faster
*** TODO Support Amazon Cloud Drive
*** TODO Support Microsoft Azure blob storage
*** TODO Support Backblaze B2
*** TODO Support [[https://wiki.openstack.org/wiki/Swift][OpenStack Swift]]
*** TODO Support Wasabi
*** TODO Support Google Drive
*** TODO Support Google Cloud Coldline
*** TODO Support Dropbox
*** TODO Support Oracle Cloud Storage
*** TODO Support IBM Cloud Storage
*** TODO Support Rackspace Cloud Files
*** TODO Consider how to backup and restore FIFO, BLK, and CHR "files"
**** c.f. https://github.com/jborg/attic/blob/master/attic/archive.py
**** c.f. https://github.com/avz/node-mkfifo (for FIFO)
**** c.f. https://github.com/mafintosh/mknod (for BLK and CHR)
* Product
** TODO Evaluate other backup software
*** TODO Check out some on App Store
**** Backup Guru LE
**** ChronoSync Express
**** Backup
**** Remote Backup Magic
**** Sync - Backup and Restore
**** Backup for Dropbox
**** Freeze - for Amazon Glacier
*** Lot of "folder sync" apps out there
** Define the target audience
*** Average home user, no technical expertise required
** Need distinquishing features
*** TODO What sets this application apart from the other polished products?
**** Linux server ready
** Windows Certified
*** CloudBerry(?) has bunches of certifications
*** is that really so meaningful? *I* never cared
** Name
*** Joseph suggests "Attic"
**** =atticapp.com= is taken
**** =attic.app= is for sale
**** Look for ~attic~ in different languages
**** Esperanto: ~mansardo~
***** also means something in Macedonian
**** Hawaiian: ~kaukau~
**** Latin: ~atticae~
* Technical Information
** Exploring other languages
*** Compile to native for easy deployment
*** Compile to native for code obfuscation
*** Rust
**** Advantages
***** compile to native
***** expressive, safe type system
***** good dependency management
***** lots of useful tools (e.g. clippy)
**** Disadvantages
***** fewer libraries compared to Go
**** DONE GraphQL server
***** Make sure it can generate a schema.json
***** Should be able to parse schema definition (for docs)
***** https://github.com/graphql-rust/juniper (BSD)
****** supports entire GraphQL specification
****** does /not/ read GraphQL schema language
****** supports GraphiQL and Playground
****** is not the HTTP server, but integrates with them
****** uses macros for schema documentation
***** tutorial at [[http://alex.amiran.it/post/2018-08-16-rust-graphql-webserver-with-warp-juniper-and-mongodb.html][alex.amiran.it]] that uses warp web framework
***** old https://github.com/nrc/graphql (MIT/Apache)
**** DONE Web framework
***** our needs are simple, so a simple framework is best
***** Actix https://actix.rs (Apache 2.0)
****** works with stable Rust
****** powerful and easy to use
****** testing library
****** integrates with juniper
****** offers state management for web code
****** lot more actively used than warp
***** warp https://github.com/seanmonstar/warp (MIT)
****** works with stable Rust
****** powerful and easy to use
****** testing library
****** integrates with juniper
***** Rocket https://rocket.rs (Apache 2.0)
****** requires Rust nightly because of fancy macros
****** routing using macros
****** streams input and output
****** cookies
****** json
****** environment configuration
****** testing library
****** integrates with juniper
***** Gotham https://gotham.rs (MIT/Apache 2.0)
****** targets stable Rust
****** routing
****** middleware
****** sessions
****** cookies
****** templates
****** testing library
****** how to integrate with juniper is unknown
***** Iron http://ironframework.io (MIT)
****** crate has not been updated since 2017
****** everything is middleware that must be added in
****** integrates with juniper
***** Nickel http://nickel-org.github.io (Express.js like) (MIT)
****** pretty basic compared to Rocket
***** pretty basic https://github.com/carllerche/tower-web (MIT)
****** competing with warp? hyper?
**** DONE Database
***** ideally want something well maintained, reliable
***** schema is pretty simple, could use key/value store
***** RocksDB https://github.com/rust-rocksdb/rust-rocksdb (Apache)
****** statically links everything, including compression support
***** SQLite https://github.com/jgallagher/rusqlite (MIT)
***** Rust wrapper to LevelDB https://github.com/skade/leveldb
***** LevelDB in Rust (active?) https://bitbucket.org/dermesser/leveldb-rs/overview
**** DONE dotenv
***** the canonical crate repo has been emptied, there are many forks of the old code
***** most-up-to-date https://github.com/apiraino/rust-dotenv (MIT)
**** DONE Configuration
***** https://github.com/mehcode/config-rs (MIT/Apache)
**** DONE =getpwuid= and =getgrgid= support
***** libc: https://crates.io/crates/libc (MIT/Apache 2.0)
**** DONE test library
***** https://github.com/rust-rspec/rspec (MPL-2.0)
****** appears to be dead
***** https://github.com/utkarshkukreti/speculate.rs (MIT)
****** works well for integration tests
**** DONE UUID support
***** https://github.com/uuid-rs/uuid (MIT/Apache 2.0)
**** DONE xattr support
***** Unix only: https://github.com/Stebalien/xattr (MIT/Apache 2.0)
**** DONE CDC
***** https://github.com/jrobhoward/quickcdc (MIT/Apache 2.0)
****** not quite FastCDC, given dates of paper, but should be close enough
****** use a constant salt value for predictable results
****** example uses =memmap= crate to read large files
**** DONE Tar file
***** https://github.com/alexcrichton/tar-rs (MIT/Apache 2.0)
**** DONE PGP/Encryption
***** https://github.com/gpg-rs/gpgme (LGPL)
****** will need to bundle the =gpgme= library (unless statically linked)
***** cryptostream https://github.com/neosmart/cryptostream (MIT)
***** basic packets [[https://github.com/csssuf/pretty-good][csssuf/pretty-good]]
***** read only [[https://nest.pijul.com/pmeunier/openpgp][pijul]] openpgp
**** DONE ULID
***** https://github.com/dylanhart/ulid-rs (MIT)
**** DONE SFTP client
***** https://github.com/alexcrichton/ssh2-rs (MIT/Apache 2.0)
**** DONE AWS client
***** Rusoto https://www.rusoto.org (MIT)
**** DONE Google Cloud client
***** https://github.com/Byron/google-apis-rs (MIT/Apache 2.0)
**** DONE Minio client
***** Rusoto supports Minio https://github.com/rusoto/rusoto (MIT)
*** Go vs Rust
**** Go: first class support for cloud services
**** Go: statically linked OpenPGP readily available
**** Go: easy to read and write language
**** Rust: mature dependency management tooling
**** Rust: cargo has good editor support
**** Rust: expressive type system
**** Rust: nominal subtyping is much easier to follow
**** Rust: streamlined error handling
**** Rust: fine-grained namespaces and visibility control
